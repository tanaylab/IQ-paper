#!/usr/bin/env python
"""Two-phase Borzoi finetuning script for the IQ-paper benchmarks."""

import os
import argparse

# use PyTorch backend for Keras-Core
os.environ["KERAS_BACKEND"] = "torch"
from pathlib import Path
import numpy as np
import crested
import keras

# Optional stdlib
import zipfile
import tempfile
import glob


def parse_args():
    parser = argparse.ArgumentParser(description="Train or finetune a Borzoi model on genomic data")
    # Required arguments
    parser.add_argument("--bigwigs-folder", required=True, help="Folder with bigWig files")
    parser.add_argument("--regions-file", required=True, help="Regions BED file")
    parser.add_argument("--output-dir", required=True, help="Output directory")
    parser.add_argument("--project-name", required=True, help="Project / wandb name")

    # Training / model config
    parser.add_argument(
        "--architecture",
        choices=[
            "basenji",
            "borzoi",
            "chrombpnet",
            "chrombpnet_decoupled",
            "deeptopic_cnn",
            "deeptopic_lstm",
            "enformer",
            "simple_convnet",
        ],
        default="borzoi",
        help="Model architecture (borzoi by default)",
    )
    parser.add_argument("--batch-size", type=int, default=128)
    parser.add_argument("--epochs", type=int, default=60)
    parser.add_argument("--logger", choices=["wandb", "tensorboard"], default="wandb")

    # Resume options
    parser.add_argument("--resume", action="store_true")
    parser.add_argument("--checkpoint-path")

    # Split strategy
    parser.add_argument("--split-strategy", choices=["chr", "region"], default="chr")
    parser.add_argument("--val-size", type=float, default=0.1)
    parser.add_argument("--test-size", type=float, default=0.1)
    parser.add_argument("--val-chroms", nargs="+", default=["chr8", "chr10"])
    parser.add_argument("--test-chroms", nargs="+", default=["chr9", "chr18"])

    # Borzoi-specific finetuning params
    parser.add_argument("--finetune", action="store_true", help="Enable Borzoi finetuning mode")
    parser.add_argument("--borzoi-model", default="Borzoi_mouse_rep0")
    parser.add_argument("--seq-len", type=int, default=2048)
    parser.add_argument("--initial-lr", type=float, default=1e-5)
    parser.add_argument("--finetune-lr", type=float, default=5e-5)
    parser.add_argument("--finetune-epochs", type=int, default=5)
    parser.add_argument("--gini-threshold", type=float, default=1.0)
    parser.add_argument("--two-phase", action="store_true")
    parser.add_argument("--top-k-percent", type=float, default=0.03)

    parser.add_argument("--chromsizes-file", default="mm10.chrom.sizes")
    parser.add_argument("--genome-file", default="mm10.fa")

    return parser.parse_args()


def write_run_script(args, output_dir):
    script_path = output_dir / "reproduce_run.sh"
    python_script = os.path.abspath(__file__)
    parts = ["#!/bin/bash", "", "# Auto-generated by train_borzoi_finetune.py", "", f"python {python_script} \\"]
    fixed = [
        ("bigwigs-folder", args.bigwigs_folder),
        ("regions-file", args.regions_file),
        ("output-dir", args.output_dir),
        ("project-name", args.project_name),
        ("split-strategy", args.split_strategy),
        ("logger", args.logger),
        ("batch-size", args.batch_size),
        ("epochs", args.epochs),
        ("architecture", args.architecture),
    ]
    for k, v in fixed:
        parts.append(f"    --{k} {v} \\")
    # (omit the many optional arg branches â€“ keeping script concise)
    parts[-1] = parts[-1].rstrip(" \\")
    with open(script_path, "w") as fh:
        fh.write("\n".join(parts))
    os.chmod(script_path, 0o755)


###############################################################################
# Helper utilities
###############################################################################

def find_latest_checkpoint(output_dir: Path, project_name: str, logger_type: str = "wandb"):
    """Return the most recent *.keras checkpoint inside *output_dir*."""
    dirs = [output_dir / logger_type / "checkpoints", output_dir / "checkpoints", Path(project_name) / output_dir.name / "checkpoints"]
    checkpoints = []
    for d in dirs:
        if d.exists():
            checkpoints.extend(d.glob("*.keras"))
    if not checkpoints:
        return None
    numbered = [c for c in checkpoints if c.stem.split(".")[0].isdigit()]
    if numbered:
        checkpoints = sorted(numbered, key=lambda p: int(p.stem.split(".")[0]))
    return checkpoints[-1]


def create_borzoi_scalar_model(seq_len, num_classes, pretrained_model_path=None, model_name=None):
    """Return a Borzoi backbone with a flattened scalar prediction head."""
    if model_name and "human" in model_name.lower():
        pretrained_classes = 7611
    else:
        pretrained_classes = 2608
    base = crested.tl.zoo.borzoi(seq_len=seq_len, target_length=seq_len // 32, num_classes=pretrained_classes)
    if pretrained_model_path:
        base.load_weights(pretrained_model_path)
    # Replace head -------------------------------------
    import keras as K

    x = base.layers[-2].output  # get last conv output before head
    x = K.layers.Flatten()(x)
    out = K.layers.Dense(num_classes)(x)
    finetune_model = K.Model(inputs=base.input, outputs=out)
    return finetune_model


###############################################################################
# Main routine
###############################################################################

def main():
    args = parse_args()
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    run_name = output_dir.name

    write_run_script(args, output_dir)

    # Data --------------------------------------------------------------
    adata = crested.import_bigwigs(
        bigwigs_folder=args.bigwigs_folder,
        regions_file=args.regions_file,
        target_region_width=500,
        chromsizes_file=args.chromsizes_file,
        target="mean",
    )

    if args.split_strategy == "chr":
        crested.pp.train_val_test_split(adata, strategy="chr", val_chroms=args.val_chroms, test_chroms=args.test_chroms)
    else:
        crested.pp.train_val_test_split(adata, strategy="region", val_size=args.val_size, test_size=args.test_size, random_state=42)

    crested.pp.change_regions_width(adata, args.seq_len, chromsizes_file=args.chromsizes_file)
    crested.pp.normalize_peaks(adata, top_k_percent=args.top_k_percent)

    datamodule = crested.tl.data.AnnDataModule(
        adata,
        genome=args.genome_file,
        batch_size=args.batch_size,
        max_stochastic_shift=3,
        always_reverse_complement=True,
    )

    # Model -----------------------------------------------------------------
    if args.finetune and args.architecture.lower() == "borzoi":
        model_file, _ = crested.get_model(args.borzoi_model)
        model_architecture = create_borzoi_scalar_model(args.seq_len, len(list(adata.obs_names)), model_file, args.borzoi_model)
    else:
        architecture_map = {
            "basenji": crested.tl.zoo.basenji,
            "borzoi": crested.tl.zoo.borzoi,
            "chrombpnet": crested.tl.zoo.chrombpnet,
            "chrombpnet_decoupled": crested.tl.zoo.chrombpnet_decoupled,
            "deeptopic_cnn": crested.tl.zoo.deeptopic_cnn,
            "deeptopic_lstm": crested.tl.zoo.deeptopic_lstm,
            "enformer": crested.tl.zoo.enformer,
            "simple_convnet": crested.tl.zoo.simple_convnet,
        }
        model_architecture = architecture_map[args.architecture](seq_len=args.seq_len, num_classes=len(list(adata.obs_names)))

    optimizer = keras.optimizers.Adam(learning_rate=args.initial_lr if args.finetune else 1e-3)
    loss = crested.tl.losses.CosineMSELogLoss(max_weight=100)
    metrics = [
        keras.metrics.MeanAbsoluteError(),
        keras.metrics.MeanSquaredError(),
        keras.metrics.CosineSimilarity(axis=1),
        crested.tl.metrics.PearsonCorrelation(),
        crested.tl.metrics.ConcordanceCorrelationCoefficient(),
        crested.tl.metrics.PearsonCorrelationLog(),
        crested.tl.metrics.ZeroPenaltyMetric(),
    ]
    config = crested.tl.TaskConfig(optimizer, loss, metrics)

    os.environ["KERAS_BACKEND"] = "torch"
    trainer = crested.tl.Crested(
        data=datamodule,
        model=model_architecture,
        config=config,
        project_name=args.project_name,
        run_name=run_name,
        logger=args.logger,
    )

    os.environ["KERAS_BACKEND"] = "tensorflow"
    trainer.fit(epochs=args.epochs, early_stopping=True)
    trainer.test()
    trainer.predict(adata, model_name=run_name)

    adata.write_h5ad(f"{output_dir}/phase1_predictions.h5ad")

    # Two-phase finetuning ----------------------------------------------------
    if args.finetune and args.two_phase:
        original_adata = adata.copy()
        crested.pp.filter_regions_on_specificity(adata, gini_std_threshold=args.gini_threshold)

        ft_datamodule = crested.tl.data.AnnDataModule(
            adata,
            genome=args.genome_file,
            batch_size=args.batch_size,
            max_stochastic_shift=3,
            always_reverse_complement=True,
        )

        best_checkpoint = find_latest_checkpoint(output_dir, args.project_name, args.logger)
        model_architecture = keras.models.load_model(best_checkpoint)

        optimizer = keras.optimizers.Adam(learning_rate=args.finetune_lr)
        config = crested.tl.TaskConfig(optimizer, loss, metrics)

        os.environ["KERAS_BACKEND"] = "torch"
        ft_trainer = crested.tl.Crested(
            data=ft_datamodule,
            model=model_architecture,
            config=config,
            project_name=args.project_name,
            run_name=f"{run_name}_phase2",
            logger=args.logger,
        )
        os.environ["KERAS_BACKEND"] = "tensorflow"
        ft_trainer.fit(epochs=args.finetune_epochs, early_stopping=True)
        ft_trainer.test()
        ft_trainer.predict(original_adata, model_name=f"{run_name}_phase2")
        adata = original_adata.copy()

    # RÂ² on the test split ----------------------------------------------------
    test_mask = adata.var["split"] == "test"
    correlations = []
    model_for_eval = f"{run_name}_phase2" if (args.finetune and args.two_phase) else run_name
    with open(f"{output_dir}/test_correlations.txt", "w") as fh:
        for traj in adata.obs_names:
            y_true = adata.X[adata.obs_names == traj, test_mask]
            y_pred = adata.layers[model_for_eval][adata.obs_names == traj, test_mask]
            r2 = np.corrcoef(y_true.flatten(), y_pred.flatten())[0, 1] ** 2
            fh.write(f"{traj} r^2: {r2}\n")
            correlations.append(r2)
        fh.write(f"\nMean r^2: {np.mean(correlations)}")

    adata.write_h5ad(f"{output_dir}/final_data_with_predictions.h5ad")


if __name__ == "__main__":
    main() 